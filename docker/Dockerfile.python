FROM python:3.11-slim

ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ARG AIRFLOW_VERSION=2.9.1
ARG PYTHON_MAJOR_MINOR=3.11
ARG AIRFLOW_CONSTRAINTS_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_MAJOR_MINOR}.txt"

# 기본 유틸
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential curl git \
    && rm -rf /var/lib/apt/lists/*

RUN pip install --no-cache-dir --upgrade pip setuptools wheel

# 파이썬 패키지
# (필요 시 팀 환경에 맞게 추가)
RUN pip install --no-cache-dir \
    pandas numpy scikit-learn \
    mlflow==2.14.3 \
    boto3 \
    pyarrow \
    matplotlib \
    google-cloud-bigquery \
    db-dtypes \
    pyspark==3.5.1

RUN pip install --no-cache-dir "protobuf<5.0.0" 
RUN pip install --no-cache-dir "mlflow==2.14.3"

# Airflow 및 관련 패키지 설치
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 1. 기초 데이터 라이브러리 먼저 설치
RUN pip install --no-cache-dir pandas numpy pyarrow boto3 psycopg2-binary

# 2. ML 및 스파크 관련 설치
RUN pip install --no-cache-dir scikit-learn mlflow==2.14.3 pyspark==3.5.1

# 3. 가장 무겁고 까다로운 Airflow를 마지막에 '제약 사항' 없이 설치
RUN pip install --no-cache-dir "apache-airflow==2.9.1" \
    apache-airflow-providers-apache-spark \
    apache-airflow-providers-amazon \
    google-cloud-bigquery db-dtypes s3fs

WORKDIR /app

# COPY src/ /app/src/


